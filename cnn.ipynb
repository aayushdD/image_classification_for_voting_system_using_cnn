{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.15.4\n",
      "tensorflow 1.12.0\n",
      "pandas 0.23.4\n",
      "cv2 3.1.0\n",
      "sklearn 0.20.1\n",
      "matplotlib 3.0.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "print('numpy', np.__version__)\n",
    "\n",
    "print('tensorflow', tf.__version__)\n",
    "print('pandas', pd.__version__)\n",
    "print('cv2', cv2.__version__)\n",
    "print('sklearn', sklearn.__version__)\n",
    "print('matplotlib', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('/home/oem/Videos/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data', 'label'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2800\n",
       "46    2000\n",
       "21    2000\n",
       "20    2000\n",
       "19    2000\n",
       "18    2000\n",
       "17    2000\n",
       "16    2000\n",
       "15    2000\n",
       "14    2000\n",
       "13    2000\n",
       "12    2000\n",
       "11    2000\n",
       "10    2000\n",
       "9     2000\n",
       "8     2000\n",
       "7     2000\n",
       "6     2000\n",
       "5     2000\n",
       "4     2000\n",
       "3     2000\n",
       "2     2000\n",
       "1     2000\n",
       "22    2000\n",
       "47    2000\n",
       "24    2000\n",
       "36    2000\n",
       "45    2000\n",
       "44    2000\n",
       "43    2000\n",
       "42    2000\n",
       "41    2000\n",
       "40    2000\n",
       "39    2000\n",
       "38    2000\n",
       "37    2000\n",
       "35    2000\n",
       "25    2000\n",
       "34    2000\n",
       "33    2000\n",
       "32    2000\n",
       "31    2000\n",
       "30    2000\n",
       "29    2000\n",
       "28    2000\n",
       "27    2000\n",
       "26    2000\n",
       "23    2000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = shuffle(df_data)\n",
    "\n",
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87120, 2)\n",
      "(9680, 2)\n"
     ]
    }
   ],
   "source": [
    "y = df_data['label']\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.1,stratify=y)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/oem/Downloads/haha/train_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-18fbd0421e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# train_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/oem/Downloads/haha/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_dir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# val_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/oem/Downloads/haha/train_dir'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a new directory\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create 2 folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # a_no_tumor_tissue\n",
    "    # b_has_tumor_tissue\n",
    "\n",
    "# val_dir\n",
    "    # a_no_tumor_tissue\n",
    "    # b_has_tumor_tissue\n",
    "\n",
    "\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join('/home/oem/Downloads/haha/', 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join('/home/oem/Downloads/haha', 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "for i in range(48):\n",
    "    i = os.path.join(train_dir,str(i))\n",
    "    os.mkdir(i)\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "\n",
    "for i in range(48):\n",
    "    i = os.path.join(val_dir,str(i))\n",
    "    os.mkdir(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.set_index('data', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of train and val images\n",
    "train_list = list(df_train['data'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transfer the train images\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = '0'\n",
    "    if target == 1:\n",
    "        label = '1'\n",
    "    if target == 2:\n",
    "        label = '2'\n",
    "    if target == 3:\n",
    "        label = '3'\n",
    "        \n",
    "    if target == 4:\n",
    "        label = '4'\n",
    "    if target == 5:\n",
    "        label = '5'\n",
    "    if target == 6:\n",
    "        label = '6'\n",
    "        \n",
    "    if target == 7:\n",
    "        label = '7'\n",
    "    if target == 8:\n",
    "        label = '8'\n",
    "    if target == 9:\n",
    "        label = '9'\n",
    "    \n",
    "    \n",
    "    if target == 10:\n",
    "        label = '10'\n",
    "    if target == 11:\n",
    "        label = '11'\n",
    "    if target == 12:\n",
    "        label = '12'\n",
    "  \n",
    "\n",
    "    if target == 13:\n",
    "        label = '13'\n",
    "    if target == 14:\n",
    "        label = '14'\n",
    "    if target == 15:\n",
    "        label = '15'\n",
    "    \n",
    "    if target == 16:\n",
    "        label = '16'\n",
    "    if target == 17:\n",
    "        label = '17'\n",
    "    if target == 18:\n",
    "        label = '18'\n",
    "   \n",
    "\n",
    "    if target == 19:\n",
    "        label = '19'  \n",
    "    if target == 20:\n",
    "        label = '20'\n",
    "    if target == 21:\n",
    "        label = '21'\n",
    "   \n",
    "    if target == 22:\n",
    "        label = '22'\n",
    "    if target == 23:\n",
    "        label = '23'\n",
    "    if target == 24:\n",
    "        label = '24'\n",
    "        \n",
    "    if target == 25:\n",
    "        label = '25'\n",
    "    if target == 26:\n",
    "        label = '26'\n",
    "    if target == 27:\n",
    "        label = '27'\n",
    "        \n",
    "    if target == 28:\n",
    "        label = '28'\n",
    "    if target == 29:\n",
    "        label = '29'\n",
    "    if target == 30:\n",
    "        label = '30'\n",
    "        \n",
    "    if target == 31:\n",
    "        label = '31'\n",
    "    if target == 32:\n",
    "        label = '32'\n",
    "    if target == 33:\n",
    "        label = '33'\n",
    "        \n",
    "    if target == 34:\n",
    "        label = '34'\n",
    "    if target == 35:\n",
    "        label = '35'\n",
    "    if target == 36:\n",
    "        label = '36'\n",
    "        \n",
    "    if target == 37:\n",
    "        label = '37'\n",
    "    if target == 38:\n",
    "        label = '38'\n",
    "    if target == 39:\n",
    "        label = '39'\n",
    "        \n",
    "    if target == 40:\n",
    "        label = '40'\n",
    "    if target == 41:\n",
    "        label = '41'\n",
    "    if target == 42:\n",
    "        label = '42'\n",
    "   \n",
    "    if target == 43:\n",
    "        label = '43'\n",
    "    if target == 44:\n",
    "        label = '44'\n",
    "    if target == 45:\n",
    "        label = '45'\n",
    "   \n",
    "   \n",
    "    if target == 46:\n",
    "        label = '46'\n",
    "    if target == 47:\n",
    "        label = '47'\n",
    "   \n",
    "   \n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('/home/oem/Downloads/IMAGE/IMAGE/PR_IMAGE/data/train', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(train_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of train and val images\n",
    "val_list = list(df_val['data'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transfer the train images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image\n",
    "    # get the label for a certain image\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    # these must match the folder names\n",
    "    if target == 0:\n",
    "        label = '0'\n",
    "    if target == 1:\n",
    "        label = '1'\n",
    "    if target == 2:\n",
    "        label = '2'\n",
    "    if target == 3:\n",
    "        label = '3'\n",
    "        \n",
    "    if target == 4:\n",
    "        label = '4'\n",
    "    if target == 5:\n",
    "        label = '5'\n",
    "    if target == 6:\n",
    "        label = '6'\n",
    "        \n",
    "    if target == 7:\n",
    "        label = '7'\n",
    "    if target == 8:\n",
    "        label = '8'\n",
    "    if target == 9:\n",
    "        label = '9'\n",
    "    \n",
    "    \n",
    "    if target == 10:\n",
    "        label = '10'\n",
    "    if target == 11:\n",
    "        label = '11'\n",
    "    if target == 12:\n",
    "        label = '12'\n",
    "  \n",
    "\n",
    "    if target == 13:\n",
    "        label = '13'\n",
    "    if target == 14:\n",
    "        label = '14'\n",
    "    if target == 15:\n",
    "        label = '15'\n",
    "    \n",
    "    if target == 16:\n",
    "        label = '16'\n",
    "    if target == 17:\n",
    "        label = '17'\n",
    "    if target == 18:\n",
    "        label = '18'\n",
    "   \n",
    "\n",
    "    if target == 19:\n",
    "        label = '19'  \n",
    "    if target == 20:\n",
    "        label = '20'\n",
    "    if target == 21:\n",
    "        label = '21'\n",
    "   \n",
    "    if target == 22:\n",
    "        label = '22'\n",
    "    if target == 23:\n",
    "        label = '23'\n",
    "    if target == 24:\n",
    "        label = '24'\n",
    "        \n",
    "    if target == 25:\n",
    "        label = '25'\n",
    "    if target == 26:\n",
    "        label = '26'\n",
    "    if target == 27:\n",
    "        label = '27'\n",
    "        \n",
    "    if target == 28:\n",
    "        label = '28'\n",
    "    if target == 29:\n",
    "        label = '29'\n",
    "    if target == 30:\n",
    "        label = '30'\n",
    "        \n",
    "    if target == 31:\n",
    "        label = '31'\n",
    "    if target == 32:\n",
    "        label = '32'\n",
    "    if target == 33:\n",
    "        label = '33'\n",
    "        \n",
    "    if target == 34:\n",
    "        label = '34'\n",
    "    if target == 35:\n",
    "        label = '35'\n",
    "    if target == 36:\n",
    "        label = '36'\n",
    "        \n",
    "    if target == 37:\n",
    "        label = '37'\n",
    "    if target == 38:\n",
    "        label = '38'\n",
    "    if target == 39:\n",
    "        label = '39'\n",
    "        \n",
    "    if target == 40:\n",
    "        label = '40'\n",
    "    if target == 41:\n",
    "        label = '41'\n",
    "    if target == 42:\n",
    "        label = '42'\n",
    "   \n",
    "    if target == 43:\n",
    "        label = '43'\n",
    "    if target == 44:\n",
    "        label = '44'\n",
    "    if target == 45:\n",
    "        label = '45'\n",
    "   \n",
    "   \n",
    "    if target == 46:\n",
    "        label = '46'\n",
    "    if target == 47:\n",
    "        label = '47'\n",
    "   \n",
    "   \n",
    "    \n",
    "    # source path to image\n",
    "    src = os.path.join('/home/oem/Downloads/IMAGE/IMAGE/PR_IMAGE/data/train', fname)\n",
    "    # destination path to image\n",
    "    dst = os.path.join(val_dir, label, fname)\n",
    "    # copy the image from the source to the destination\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('/home/oem/Downloads/flower/train_dir/2')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/oem/Downloads/haha/train_dir'\n",
    "valid_path = '/home/oem/Downloads/haha/val_dir'\n",
    "\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 16\n",
    "\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87120 images belonging to 48 classes.\n",
      "Found 9680 images belonging to 48 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen= ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,rotation_range=90,zoom_range=0.2, width_shift_range=0.1,height_shift_range=0.1,shear_range=0.05,channel_shift_range=0.1)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(96,96),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical', shuffle =True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(96,96),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_gen = datagen.flow_from_directory('/home/oem/Downloads/IMAGE/IMAGE/PR_IMAGE/data/test/',\n",
    "                                        target_size=(96,96),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96,96, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(48, activation = \"softmax\"))\n",
    "\n",
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 92, 92, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 92, 92, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 92, 92, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 44, 44, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 42, 42, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 19, 19, 128)       73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 128)       147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 48)                12336     \n",
      "=================================================================\n",
      "Total params: 2,398,768\n",
      "Trainable params: 2,397,424\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='RMSprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 3.4376 - acc: 0.0933\n",
      "Epoch 00001: val_acc improved from -inf to 0.07479, saving model to model.h5\n",
      "2723/2723 [==============================] - 2487s 913ms/step - loss: 3.4373 - acc: 0.0933 - val_loss: 3.5259 - val_acc: 0.0748\n",
      "Epoch 2/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.9922 - acc: 0.3193\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.07479\n",
      "2723/2723 [==============================] - 2449s 899ms/step - loss: 1.9920 - acc: 0.3194 - val_loss: 8.8485 - val_acc: 0.0564\n",
      "Epoch 3/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.5414 - acc: 0.4447\n",
      "Epoch 00003: val_acc improved from 0.07479 to 0.65072, saving model to model.h5\n",
      "2723/2723 [==============================] - 2531s 929ms/step - loss: 1.5413 - acc: 0.4448 - val_loss: 1.1712 - val_acc: 0.6507\n",
      "Epoch 4/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.4463 - acc: 0.4780\n",
      "Epoch 00004: val_acc improved from 0.65072 to 0.68151, saving model to model.h5\n",
      "2723/2723 [==============================] - 2513s 923ms/step - loss: 1.4466 - acc: 0.4780 - val_loss: 1.0359 - val_acc: 0.6815\n",
      "Epoch 5/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.4056 - acc: 0.4934\n",
      "Epoch 00005: val_acc improved from 0.68151 to 0.71839, saving model to model.h5\n",
      "2723/2723 [==============================] - 2477s 910ms/step - loss: 1.4055 - acc: 0.4935 - val_loss: 0.9849 - val_acc: 0.7184\n",
      "Epoch 6/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.3502 - acc: 0.5143\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71839\n",
      "2723/2723 [==============================] - 2441s 896ms/step - loss: 1.3502 - acc: 0.5143 - val_loss: 0.9717 - val_acc: 0.7102\n",
      "Epoch 7/17\n",
      "2722/2723 [============================>.] - ETA: 0s - loss: 1.3241 - acc: 0.5255\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71839\n",
      "2723/2723 [==============================] - 2445s 898ms/step - loss: 1.3242 - acc: 0.5255 - val_loss: 0.9686 - val_acc: 0.7145\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystopper = EarlyStopping(monitor='val_acc', patience=2, verbose=1)\n",
    "reducel = ReduceLROnPlateau(monitor='val_acc', patience=1, verbose=1, factor=0.1)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=17,\n",
    "                   callbacks=[reducel, earlystopper, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9669851359257028, 0.7240702479338843]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator=val_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 32s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "test_gen.reset()\n",
    "pred=model.predict_generator(test_gen,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2025680e-02, 1.8857944e-01, 1.9320570e-02, ..., 9.3687058e-04,\n",
       "        1.3058367e-03, 4.4449302e-03],\n",
       "       [1.3932608e-04, 1.5531887e-16, 4.6522929e-15, ..., 6.4242313e-13,\n",
       "        3.3393123e-13, 1.2330936e-13],\n",
       "       [9.8689878e-01, 1.9205681e-09, 9.2419228e-09, ..., 1.1482610e-14,\n",
       "        1.0352336e-12, 2.3034896e-10],\n",
       "       ...,\n",
       "       [7.9878252e-03, 1.6536790e-09, 4.8086461e-02, ..., 1.4511234e-01,\n",
       "        3.8157699e-01, 2.8954527e-01],\n",
       "       [2.0244755e-03, 6.8535141e-05, 3.2750389e-01, ..., 2.9259196e-02,\n",
       "        1.7175490e-01, 3.5034588e-01],\n",
       "       [1.5289236e-03, 3.5544554e-06, 1.0256342e-01, ..., 1.4091246e-01,\n",
       "        3.5840237e-01, 3.1703672e-01]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_gen.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_gen.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results1.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TGPU",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
